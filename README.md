## Hi, I'm Himel ğŸ‘‹

I'm a **Machine Learning enthusiast** with a strong interest in **research**, particularly in the areas of **distributed and federated training**, **communication-efficient model optimization**, and **scalable learning systems**.

I enjoy working on projects that bridge the gap between **theory and systems**, focusing on how ML models can be trained efficiently across **heterogeneous edge and cloud environments**. My work involves designing algorithms that tackle **non-IID data, resource heterogeneity**, and **scalability challenges** in collaborative learning, especially within **IoT ecosystems**.

I'm currently exploring:
- ğŸ¤– LLMs for NLP and generative AI
- ğŸ§¿ Digital Twin for real-time IoT and edge intelligence
- âœ¨ Federated & Split Learning
- âš™ï¸ System-aware ML optimization
- ğŸ“¶ Communication-efficient training
- ğŸ“š ML in real-world, distributed scenarios


