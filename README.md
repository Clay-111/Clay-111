## Hi, I'm Himel 👋

I'm a **Machine Learning enthusiast** with a strong interest in **research**, particularly in the areas of **distributed and federated training**, **communication-efficient model optimization**, and **scalable learning systems**.

I enjoy working on projects that bridge the gap between **theory and systems**, focusing on how ML models can be trained efficiently across **heterogeneous edge and cloud environments**. My work involves designing algorithms that tackle **non-IID data, resource heterogeneity**, and **scalability challenges** in collaborative learning, especially within **IoT ecosystems**.

I'm currently exploring:
- 🤖 LLMs for NLP and generative AI
- 🧿 Digital Twin for real-time IoT and edge intelligence
- ✨ Federated & Split Learning
- ⚙️ System-aware ML optimization
- 📶 Communication-efficient training
- 📚 ML in real-world, distributed scenarios


